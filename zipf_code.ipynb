{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zipf's Law\n",
    "\n",
    "In the 1930s, the American Linguist George Kingsley Zipf studied the frequency of word usage in different languages and published his findings in his works \"The Psycho-Biology of Language\" and \"Human Behavior and the Principle of Least Effort\" in which he formulated the so called Zipf's law. This law is an empirical rule that describes the frequency distribution of words in a language, cities by population, and various other phenomena. \n",
    "\n",
    "In the context of linguistics, if you list words by their frequency of occurrence in a large corpus, the most frequent word will occur twice as often as the second most frequent word, three times as often as the third most frequent word, and so on. \n",
    "\n",
    "Mathematically, this means that the frequency $ f $ of the $k$-th ranked item is given by:\n",
    "\n",
    "$$ f(k) \\approx \\frac{C}{k^{s}} $$\n",
    "\n",
    "where:\n",
    "\n",
    "- $f(k)$ is the frequency of the k-th item;\n",
    "- $k$ is the rank of the item;\n",
    "- $C$ is a constant;\n",
    "- $s$ is a parameter that typically is close to 1. Known as scaling exponent, it controls the rate at which the frequency of items decreases as their rank increases.\n",
    "\n",
    "This idea has some interesting consequences in statistics since it creates a discrete probability distribution that describes the frequency of elements in a set. This is known as Zipf Distribution.\n",
    "\n",
    "\n",
    "# Motivation\n",
    "\n",
    "This notebook aims to demonstrate the Zipf's Law by using PySpark and some others frameworks like Matplotlib. The data used in this code are avaiable freely in Project Guntemberg website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The book used in this example will be The Three Musketeers of Alexandre Dumas. So, firstly, the data - in this case, the book - must be loaded as a DataFrame of PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/18 14:13:40 WARN Utils: Your hostname, linux resolves to a loopback address: 127.0.1.1; using 192.168.10.105 instead (on interface wlp4s0)\n",
      "24/07/18 14:13:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/18 14:13:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ZipfLaw\").getOrCreate()\n",
    "df = spark.read.text(\"musketeers.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = df.selectExpr(\"explode(split(value, ' ')) as word\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
